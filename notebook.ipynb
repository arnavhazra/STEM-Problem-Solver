{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import wolframalpha\n",
    "import openai\n",
    "import re\n",
    "\n",
    "# Wolfram Alpha credentials\n",
    "client = wolframalpha.Client('EHPL84-R8JVY7PT9W')\n",
    "\n",
    "# OpenAI credentials\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes queries through the Wolfram Alpha Short Answers API\n",
    "def wolframQuery(userInput):\n",
    "    # Define the API endpoint URL and the query parameters\n",
    "    api_url = \"https://api.wolframalpha.com/v1/spoken\"\n",
    "    params = {\n",
    "        \"appid\": 'EHPL84-R8JVY7PT9W',\n",
    "        \"i\": userInput\n",
    "    }\n",
    "    # Send the HTTP request to the API endpoint\n",
    "    response = requests.get(api_url, params=params)\n",
    "    # Check if the request was successful (i.e., HTTP status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Print the short answer returned by the API\n",
    "        return f\"According to Wolfram Alpha, {response.text}\"\n",
    "    else:\n",
    "        # Print the error message returned by the API\n",
    "        return f\"Error: {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function processes user input through the ChatGPT API\n",
    "def GPTQuery(myInput):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.2,   # Lower temperature values make the output less random\n",
    "        max_tokens=256,\n",
    "        # Instruct the model on how to process certain inputs:\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. However, if you're asked to provide an answer \"\n",
    "                                          \"to a calculation or purely factual or analytical question that could \"\n",
    "                                          \"reasonably be answered by Wolfram Alpha, delegate to Wolfram Alpha instead \"\n",
    "                                          \"by outputting a query that Wolfram Alpha would understand. Indicate this \"\n",
    "                                          \"scenario by formatting the output exactly like this: Query for \"\n",
    "                                          \"WolframAlpha: <query>\"},\n",
    "            {\"role\": \"user\", \"content\": myInput},\n",
    "        ]\n",
    "\n",
    "    )\n",
    "\n",
    "    chatGPTresponse = completion.choices[0].message.content\n",
    "\n",
    "    # Checks to see if ChatGPT's response needs to be passed to Wolfram Alpha\n",
    "    if \"Query for WolframAlpha:\" in chatGPTresponse:\n",
    "        properWolframQuery = chatGPTresponse.replace(\"Query for WolframAlpha:\", \"\")\n",
    "        return wolframQuery(properWolframQuery)\n",
    "    # If not, return ChatGPT's response\n",
    "    else:\n",
    "        return chatGPTresponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    while True:\n",
    "        prompt = input(\"You: \")\n",
    "        promptNew = prompt.lower()\n",
    "\n",
    "        # Allows the user to override ChatGPT processing and process through Wolfram Alpha if a basic calculation is\n",
    "        # entered or the user adds the word \"wolfram\" to their query\n",
    "        if re.search(r\"(\\d+[\\+\\-\\*\\/])+\\d+\", promptNew) or \"wolfram\" in promptNew:\n",
    "            result = wolframQuery(promptNew)\n",
    "            print(result)\n",
    "\n",
    "        else:\n",
    "            myResponse = GPTQuery(promptNew)\n",
    "            print(f\"ChatGPT: {myResponse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
